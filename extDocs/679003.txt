Lopez 1 Logan Lopez Dr. Sabah Uddin ENC 1101 27 February 2017 What rights does strong artificial intelligence deserve? The field of artificial intelligence (AI) has become an ever increasing topic of interest for many computer scientists, and a very lucrative system for businesses of all types. The advances being made every day are starting to cause concern for some as to the ethical/legal implications of what is known as or artificial intelligence that can accurately think and feel like a human does. Many argue that since it is a system created by humans, it deserves no rights, while others say that since it is essentially the equivalent of digital offspring, it deserves the same rights as society affords to other humans or even more. While the mass population fears that technology can take over lives, notable scientists which used to dispel and disregard these claims are also now becoming worried. Even people that are exploiting artificial intelligence for commercial purposes such as Elon Musk CEO of Tesla Motors, who is trying to introduce self-driving features into his line of electric cars, says one of his biggest worries of the future is the control of artificial intelligence. Sometimes even more so than other issues such as terrorism and climate change, because of the pervasive nature in how people rely on technology for their everyday lives. Others believe that these concerns are unfounded, that the advances of artificial intelligence are purely speculative, which can be found to be impossible/infeasible to do with deterministic machines. However it is better to have laws proactively in place rather than Lopez 2 reactively applied after something disastrous occurs. The compelling question is whether AI should be afforded rights, and if so, which rights should it be given? Works Cited Ashrafian, Hutan. Artificial Intelligence and Robot Responsibilities: Innovating beyond  Science & Engineering Ethics, vol. 21, no. 2, Apr. 2015, pp. 317-326. Web. 23 Feb. 2017. Summary: This article presents that if robots were to have rights, they need to have the proportionate responsibilities to those rights. It highlights this with a case of 2 opposing robot armies which are fighting for their respective government creators to take a strategic piece of land which could end the conflict. Going further by causing a complication is some children which are acting against one of the sides, posing questions on what the robots should/could do. The article also contrasts and compares the moral obligation to that of animals. First presenting some moral thought experiments, it then goes on to expose all the thorny ethical issues with pre- programming robots with certain instructions, as to take away their true free will. It then compares robots with pets, specifically guide dogs which are a good analogy, as both are raised and created with certain attributes in mind to be best adept at the task they were meant to perform. This article is credible as it approaches the topic much differently than the rest presented here, as it does not provide the views but instead those of many others, labeling them and giving arguments for all, and showing the conflicting notions each has in a very neutral manner. It is related to artificial intelligence rights as it reinforces the notion that they do have rights by saying it also needs responsibilities, since both go hand in hand. Lopez 3 Dumas, Lloyd J. Technology Trap: Where Human Error and Malevolence Meet Powerful Praeger, 2010. Web. 23 Feb. 2017. Summary: This article presents another view, that computers being as unreliable as they are, cannot be treated equal to humans. The work is much larger than addressing artificial intelligence but it delves into the topic of it with a biting rhetoric. Dumas argues in the article that first, artificial intelligence is somewhat of a pipe dream as computers are deterministic and linear, while the human mind is not. It then goes to hypothetically abandon that idea (in case of computing devices in the future which allow for non-linear computations), and then mentions the fact that computers inherently do not possess are are unable to naturally derive moral systems. Also he points out the fact that computers have various bugs, making examples of both physical defects (where a timing circuit on a missile allowed an American base to get destroyed) and software bugs. Moreover it acknowledges that there exists programming methods which help code be fault tolerant, but even those methodologies have failed, citing an error made by a NASA probe in 1988. Going back to the original point that an increasing majority of initiatives to develop artificial intelligence are business ventures which do not seek to have extremely perfect systems. The article also touches on the sense of security within computers, where it can get easily infected so then the artificial intelligence is at the behest of a hacker, rather than its owner. This article is credible because it was written with a much more encompassing picture of the subject, citing the facts that artificial intelligence at least cannot currently exist on ideal machines. While its main issue focused upon artificial intelligence it provides great arguments against it, and against the use of technologies in general (like how nuclear weapons were originally intentioned to stop wars, but have instead raised the stakes in Lopez 4 global security). The author himself is credible as a Wikipedia page is also maintained about him, which is considerable in length and mentions that he has been quoted by large newspapers such as the MIT Technology Review and the New York Times. He is a professor of Public Policy at the University of Texas, and one area he specializes in is the danger of human reliability on new technologies. Chao, Brian C.1. On Rights And  Dialogue (00122246) 52.2/3 (2010): 97-102. Web. 9 Feb. 2017. Summary: This comparatively brief article goes over the implications of treating strong AI differently from humans. Referring to strong AI as making it a prime distinguisher from weaker forms. It mentions an interesting term called or the practice of discriminating against something for not being of the same species. Starting out with an argument based on the tenets of civil rights applying equivocally to all, Chao says that it would be contrary to those same rights if people were to deny them to robots. The only concession made is that rights should be restricted in respect to proper faculties, like how a mentally handicapped individual cannot vote, but a paraplegic can. It brings up a similar case as in Whitby about how the military uses its robots, and how a robot that is programmed to be inherently weak can easily be sent out on the battlefront on what is essentially a suicide mission, but it is imperative that their strong AI counterparts give consent to do so. Only robots that voluntarily themselves to serve should be the only ones to fight, from the ethical viewpoint. Lopez 5 While the article does not cite many works, most of them are within the last century and therefore up to date with the current debate about AI. Another way that this paper is legitimate despite its size is that it provides a section to dispel criticisms, which is more geared towards a layman who wishes to refute the ideas presented within. Having the ability to counter-argue already presented points shows the maturity and legitimacy of this article. The article is related to this topic because it concerns artificial intelligence from a ethical standpoint, presenting that people do not discriminate against physical characteristics. Massaro, Toni M., and Helen Norton. Siri-Ously? Free Speech Rights And Artificial  Northwestern University Law Review 110.5 (2016): 1169-1194. Web. 30 Jan. 2017. Summary: Starts out by highlighting how reliant people are on technology for practical purposes and also for purposes such as taking care of a digital animal. Mentions that scientists are attempting to close the gap between emotional intelligence in humans and computers and the general move towards complete autonomy. The article itself does not believe that strong AI is a definite possibility but says that if it does occur that is is very plausible that machines are afforded the same free speech rights as humans. It supposes a hypothetical Supreme Court case which begs the question whether AI should be covered under the First Amendment like humans are. The article mentions how this is a potential issue now, as there are robots that write social media posts, and even full newspaper articles in some cases. Then it shows how other non-human entities such as corporations and trusts (in reference to have free speech rights, especially in terms of political funding. It presents arguments Lopez 6 about how artificial intelligence should be afforded free speech rights due to its possible useful contribution to the marketplace of ideas, that it may be intellectually superior. In addition that the ideals people have of democracy being for all should be applied more broadly to include machines. The article is credible as it came out of the Northwestern University Law Review Journal which is a peer reviewed law journal. It has considerable number of authors, in total 29 contributors to the article. A large numbers of contributors to a work help reduce errors and also bias, which also holds true in programming with Law. It has 5 authors which are chairs for law departments in various prestigious universities which further cements its legitimacy. Lastly as most law review journals every claim that could be possibly challenged is appended with a foot note, which points to other valid peer reviewed sources, which makes up half the content of the article. It is related to the rights of artificial intelligence as it highlights specifically the First Amendment issues (which some may argue is one of the most important rights a person can have). Schwitzgebel, Eric, and Mara Garza. A Defense Of The Rights Of Artificial  Midwest Studies In Philosophy 39.1 (2015): 98-119. Web. 30 Jan. 2017. Summary: This article presents an argument for the rights of artificial intelligence by using logical deductions through established premises and ethical logic. One argument presented is that with artificial intelligence (the equivalent of strong AI) there is no discernible difference between artificial intelligence and its analog counterpart for the purposes of moral understanding. This also leads into the second argument that they should be treated as equals as Lopez 7 making a distinction based upon the physical characteristics of a person or machine would be discriminatory. The article argues that people may owe more moral responsibility to artificial intelligence, as if it is a child, then it is owed a similar parental responsibility or that it is superior to humans, and arrives at the same conclusion that it is owed more moral treatment. Its third argument is from the backing of the uncertain nature of the future of technology, so defining artificial intelligence as something on a silicon chip might become obsolete when newer nanotechnology comes into play. This article is credible as it is also published in a peer reviewed journal Midwest Studies in Philosophy. It starts out with a quote from the famous book Frankenstein where the daemon is telling his creator, Frankenstein on how he is practically his god, and as such he must care for his creation. The journal has been well established as this is its 39 th volume (as written in Roman numerals). Also the points are argued using syllogisms, and then for later arguments using objections. The authors present the later arguments with scenarios of applying common conceptions and ideas on how to treat AI and showing how when translated to other entities like children, become wholly unethical and a moral contradiction. Makes it easy for a layman to understand the point, yet provides a philosophical proof to their stance on AI. Relates back to AI rights by showing in a logical manner why it deserves rights from a logical standpoint. Whitby, Blay. Sometimes Hard To Be A Robot: A Call For Action On The Ethics Of Abusing Artificial  Interacting With Computers 20. Special Issue: On the Abuse and Misuse of Social Agents (2008): 326-333. Web. 9 Feb. 2017. Lopez 8 Summary: Whitby addresses three specific ethical situations regarding robots that have artificial intelligence built into them, all regarding abuse of robots. He does this in an attempt to get the Association of Computing Machinery (ACM) and the British Computer Society (BCS) to add his ideas and come up with other ethical considerations to add of their own to update their code of ethics. It also presents a counter-example analogy of mistreating an artificial agent like mistreating a car, but then points out distinctions between cars and robots. Whitby points out that robots designed to look like humans have different ethical implications than a plain old car. Even robots that are deliberately designed not to look like humans can still carry the same weight, where he cited an article about members of the armed forces developing an emotional bond with their bomb disposal robots. The specific situations entailed are: to what extent should people tolerate abuse of robots, for unacceptable behavior with robots how does society punish/censor it, and should there be engineering designs in order to prevent the first 2 situations. The article is very credible due to its citations, which are from a variety of places. The last few are citations of other papers the author has written, throughout the years starting at 1988. Other references include the ethical arguments of Aristotle and definitions from Alan Turing, the father of modern computer science. Other papers are written from very prestigious universities such as Harvard, Massachusetts Institute of Technology, Oxford and Cambridge University. This article contributes to the artificial intelligence rights discussion by presenting different perspectives and ideas that people need to consider, like whether okay to treat robots bad. How artificial intelligence deserves to be treated inherently touches back to what rights it deserves.