Lopez 1 Logan Lopez Dr. Sabah Uddin ENC 1101 11 April 2017 The changing dialog of artificial intelligence rights Artificial intelligence is an implementation of the intellect of the human mind into the programming and framework of a computer, allowing it to do reasoning and other thought processes that humans take for granted. Strong artificial intelligence refers to the broad replication of the human mind which includes emotions, preferences, and personality, essentially being a digital brain of sorts. Papers that were written closer to 2000 take on a very defensive tone to explain and reason the rights that the authors believed artificial intelligence inherently had. However since artificial intelligence still seemed like a big possibility rather than reality, most also stipulated that it was in case (artificial intelligence which can accurately mimic the human mind) had fully come to fruition. Papers that are closer to current times reflect a notion that strong AI has grown from a plausibility to an emerging reality, and making remarks of how there are already situations that are arising which need to have established precedent now. Later authors are saying we no longer have the luxury of a what-if but need to have laws in place to deal with the coming future which will be within the next projected decade. The rhetoric and diction used to talk about the rights of artificial intelligence over time have evolved and started focusing on different aspects such as the viability of AI and the tone in which was used to justify positions on the rights of AI. To begin with, articles closer to the beginning of the millennium were emphasized much Lopez 2 more on the justification of their positions, rather than taking into account the possible details and specific scenarios which may arise with strong AI. In contrast, later articles made it more of an assumption that once strong AI has emerged it would be automatically given rights, and instead started to focus on other issues branching from there, such as responsibilities to match those rights, or even how we should handle ethical interaction between different artificial intelligence systems. One article published in 2015 titled Intelligence and Robot Responsibilities: Innovating Beyond by Hutan Ashrafian reflects the assumption that robots (or AI) will be awarded rights, and instead discusses how to program ethical mechanisms to attempt to prevent abuses from artificial intelligence. It begins by using an example of 2 warring robot armies which encounter a third belligerent which are indigenous children (Ashrafian 1). It proposes first the stipulation that since humans have rights and respective responsibilities then giving artificial intelligence rights means it must carry responsibilities too. The author then poses certain questions relating to the moral example outlined at the beginning of the paper with examples of whether the robots should have aided the children when they became injured, at the cost of prolonging the war for land they were fighting. This shows that instead of debating whether artificial intelligence deserves rights, scholars are now jumping on what to do about the consequences of giving them rights which is much different than earlier papers. Earlier papers such as the abuse and misuse of social by Blay Whitby, a distinguished writer of artificial intelligence rights, presents an approach that focuses on justifying why artificial intelligence deserves rights. Whitby also makes some very good comparisons on allowing someone to abuse their car, which is their property so something like Lopez 3 ought not to rev the engine so hard or spin the contains a not a (Whitby 327) which shows it purely is a personal choice which affect the longevity of the property. While contrasting it with child abuse, which might be under the responsibility and control of the parent, is morally abhorrent and grounds to revoke parental rights. Touching also on topics like what kind of abuse of human like robots should be tolerated, or robots in general as it may lead down a slippery slope to more anti-social behaviors, similar to concerns that some raise about violent video games (Whitby 329). Elaborating on this he shows that the issues that artificial intelligence are very thorny and cannot be thought of in a quick quip, but rather through extensive discussion among respectable scientists. He puts this task to the Association for Computing Machinery and the British Computer Society which define the ethical codes of conduct for programmers in the United States and Britain, respectively. Scholarly papers closer to the start of the millennia really doubted the veracity of claims that strong AI was an inevitability, and some outright refused to even acknowledge a possibility that it could be developed. Such as in the article by Lloyd Dumas, titled Technology Trap: Where Human Error and Malevolence Meet Powerful he shows how our current infrastructure and basic nature of computers makes AI inherently a pipe dream. Reminding readers that computers are not perfect machines (as much as it pains computer scientists of this fact) but instead crash, freeze, become obsolete, and can be hacked and commandeered by others. To even think of creating artificial intelligence if the possibility arises would be a reckless act in the eyes of the author, as a malevolent machine can easily manipulate power grids and other essential infrastructure to demise. He also presents that nothing lives in a vacuum, and that programmers are not looking to make essentially perfect programs, but that programs Lopez 4 that work most of the time, which in the case of artificial intelligence would not really work out when trying to emulate the complicated nature of the human mind. These perspectives were written in 2010, which is almost a decade ago highlighting the previous tone of papers within the timespan. More recent articles such as one from 2015 named Defense of the Rights of Artificial writes as if strong AI has already been invented. Making many assumptions about the state of artificial intelligence in the future, like having no discernible difference from human intellectual activity (Garza 99). Then going on to say how it would be myopic to define artificial intelligence as or based upon silicon chips as might leave silicon behind as it previously left vacuum tubes behind, perhaps in favor of nanotech carbon (Garza 102) which demonstrates the uncertainty of the path of technological evolution. This article demonstrates the growing expectations of many that artificial intelligence is just beyond the current technological frontier. To conclude, the debate about artificial intelligence rights and artificial intelligence in general has greatly changed over time, include the tone, assumptions, and topics focused on. Papers in the past focused more on whether it was plausible for strong AI to develop and consequently whether we needed to consider rights for it. Also authors who believed in the rights of artificial intelligence were much more logical and defensive on their stances. Later papers lean on more assuming that the reader has at least come across some argument for AI rights, and then glosses over it to go over details which were not presented before, such as how to prevent abuse of robots and from robots. Overall it seems the trend of scholarly discourse over artificial intelligence and its rights have become more accepting and assuming its inevitability. Lopez 5 Works Cited Ashrafian, Hutan. Artificial Intelligence and Robot Responsibilities: Innovating beyond  Science & Engineering Ethics, vol. 21, no. 2, Apr. 2015, pp. 317-326. Dumas, Lloyd J. Technology Trap: Where Human Error and Malevolence Meet Powerful Praeger, 2010. 116-133. Schwitzgebel, Eric, and Mara Garza. A Defense Of The Rights Of Artificial  Midwest Studies In Philosophy 39.1 (2015): 98-119. Whitby, Blay. Sometimes Hard To Be A Robot: A Call For Action On The Ethics Of Abusing Artificial  Interacting With Computers 20. Special Issue: On the Abuse and Misuse of Social Agents (2008): 326-333.