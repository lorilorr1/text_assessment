Edward Rivera Carr ENC1101 5/2/17 Project 3: The Necessity of Quantum Computing for Technology to Evolve Technology has done nothing but increase at an astounding rate for the past century. You go more than a year without some major improvement in everyday items, going from rotary telephones to tiny computers in our pockets in a matter of 30 years, or vehicles that run completely on electricity. It seems in the last few years though that we seemed to have reached a point of stagnation. While things like phones do get incremental changes on an annual basis, there been any big change such as going from flip phones to going completely touch screen. Technology is currently in a state where companies and business ventures are stuck adding small tweaks to already great inventions. What could possibly get us out of this slump? How about a new technology that is able to process information on global, even galactic, levels? Or something that could learn without human interaction or updates? Ever heard of a quantum computer? computing is a new field of science aiming to use quantum phenomena in order to perform operations on (Barila 1) Quantum computing is a necessity for humankind to get out of the stagnant status of technology we are currently experiencing. With the use of quantum computing, we can overcome obstacles that were physically and digitally impossible for us.There are three main reasons why the capabilities of quantum systems: 1) big data processing, 2) large scale problem solving, and 3) the ability for quantum computers to learn from previous data. The amount of raw processing power available in quantum computers goes beyond what current supercomputers (very powerful, non-quantum computers) are capable of due to the of two state quantum systems called qubits. Unlike the bits in computers which can be either 0 or 1, qubits can be placed in arbitrary superpositions + and entangled with each (Fowler 1). In simpler terms, a qubit can be a 1 and a 0 at the exact same time. Data from millions of different sources could be processed in mere seconds just because of the availability of that third bit variable. This is where large scale problem solving comes in. As I mentioned before, we are constantly looking for ways to improve current technology. Using information from many different companies, we can feed it into a quantum computer and allow it to look at the data to find more efficient ways to make things. This is important since one of the biggest factors stopping technological advancement is the high cost of more powerful technology. This is where the final, and arguably the most important, point comes in: the ability for the quantum computer to teach itself how to better deal with this data. Quantum systems are able to find trends in the data, and figure our where to improve, allowing for technology to be found on the fly, things we could never dream of. to classical computing, quantum algorithms are developed long before any large-scale practical quantum computer is physically (Lee 1) This is where the counterargument can be made. There are no viable quantum computer available to prove this theorem. We have not needed quantum computing thus far to make any of our current advancements, but it usually takes the finding of a new technology to allow for the flourishing of society. Just look at what the industrial revolution did for the entire world. When one thinks of quantum computing, hard to not think of things such as computers at NASA, Skynet from the Terminator series, or popular talking such as HAL or Nightrider. This makes complete sense since it sounds like a quantum computer should be capable of anything. There is a bit of truth in that statement. As mentioned before, qubits are the biggest factor in what a quantum computer can actually do. The availability of superposition (the ability for an item in a quantum field to be in two different states at the same time) as a concept allows for more data to be processed at once. not just that quantum computers are inherently more powerful than a normal computer (which they are), they also have much less to process at once compared to traditional algorithms and data. Traditional data works off a data multiplier of the number of bits available squared, meaning 8 bits of classical data can be any one of 64 possible combinations of data at a time based on those 8 bits of data either being 1 or 0, but never both. Since qubits can be both at the same time, because of superposition, that number of possible combinations exponentially increases with each added qubit. Essentially, the exponent of the 2 multiplier is equal to the number of qubits available (i.e. 8 qubits has a multiplier of 2 to the power of 8, or 256, possible combinations.) Well, what does that mean? To make it simple, much less space is required for a qubit to exist since it can hold more data as compared to classical data. To make a better comparison, 20 qubits can contain the same amount of information as a little over 1,000,000 bits of regular data. Just 20. mind-boggling. Now that big number crunching point makes more sense. The amount of data, when converted to qubits to be processed by a quantum computer, is condensed to a fraction of its previous size, meaning it takes much less time for the computer to convert the data into videos, 3-D renders, or large scale photos (meaning pictures of very high resolutions such as 100 megapixels). This will increase our efficiency as a technologically minded species allowing as to spend less time on on data processing, and more on data examining. The next two points can go hand-in-hand, self learning and problem solving. almost a scary thought that a computer could have the ability to teach itself new concepts, even ones that had not been invented yet. This has already happened though. In 2011, IBM introduced the first DeepQA product, Watson. Watson is a question answering machine with over 4 terabytes of available data to access that allows it to answer most questions with relative ease. To prove its use, IBM pit Watson in a game of Jeopardy against two previous winners and was able to outperform both of them and win the top prize of $1 million. This is just data retrieval based off vocal inputs. Quantum computers would make Watson look like a toaster in comparison. Not only could they use data like Watson to answer questions, they could propose new answers to the questions as a way of solving them faster. because of access to deep learning algorithms and that allow quantum computers to learn and regurgitate the data it does learn. been asked is the next big I knew I would already be doing (Krauss) Quantum computing as a viable field of scientific research is still a murky subject. Everything that has been presented so far has been nothing more than conjecture based off research and data. hard to convince someone of the need for something that has neither been needed or used before. Most great technological advances are because of a reliance on one another to continue in a progressive fashion. In fact, if it was not for the advent of mass manufacturing and coal power that came about because of the Industrial Revolution, we would probably be still using oil lamps to light our households. Families were able to earn a normal income working for employers that hired hundreds of workers to fill factories and keep production lines moving, allowing for cheaper products and increased spending, helping spur the economy. More money in the economy also meant more government funding, allowing previously expensive projects to be tangible. The keyword to look for here though is a previously unheard of change that shakes the foundations of society, usually for the better. We need a new one. We are reaching a plateau on our way to the mountaintop of technology. We, as a race, are in need of something new to come in and help motivate and teach us on how to better improve what we already have while also creating something brand new altogether. Bibliography: A. a. (2015). Quantum Computing - A New Implementation of Simon Algorithm for 3-Dimensional Registers. Journal Of Applied Computer Science & Mathematics, (19), 23-30 Fisher, A. J. (2003). Quantum Computing in the Solid State: The Challenge Decoherence. Philosophical Transactions: Mathematical, Physical and Engineering Sciences, (1808). 1441. Lee, Y. H., Khalil-Hani, M., & Marsono, M. N. (2016). An FPGA-Based Quantum Computing Emulation Framework Based on Serial-Parallel Architecture. International Journal Of Reconfigurable Computing, 1-18. Fowler, A. G., Thompson, W. F., & Yan, Z. (2008). Long-range Coupling and Scalable Architecture for Superconducting Flux Qubits. Canadian Journal Of Physics, 86(4), 533- 540 Quantum Computers Explained Limits of Human Technology Kurzgesagt - https://www.youtube.com/watch?v=JhHMJCUmq28 Lawrence Krauss: Quantum Computing Explained bigthink - https://www.youtube.com/watch?v=UUpqnBzBMEE