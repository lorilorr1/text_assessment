Lopez 1 Logan Lopez Dr. Sabah Uddin ENC 1101 25 April 2017 Why artificial intelligence rights must be handled carefully Artificial intelligence (AI) is the programmatic replication of human deductive and inductive reasoning along with recognizing patterns through intuition. Strong AI is the accurate mimicry of the human mind in terms of emotions, wants/desires, and personality. Many scholars say that artificial intelligence which can achieve an equatable level of consciousness such as humans should be given equal rights as humans. However many of these are very concerned with more of the theoretical and ethical implications of rights surrounding AI, while not taking into account the practical and safety concerns of doing so. Giving strong artificial intelligence rights would be counter-intuitive, dangerous, and ill-advised as they are not restricted by the same physical limitations as humans are, and by consequence cannot share in moral values. Artificial intelligence is by definition artificial, which brings up a lot of issues if society is going to give it rights, namely that it be duplicated, and has an infinite lifespan. Humans do not live forever so they place value of life and existence at a much higher priority than a machine would, which is already an inherent difference which could lead to catastrophic problems. This also is a major concern for both laymen and computer experts alike (such as Elon Musk, Stephen Hawkings, and Bill Gates) is the notion of a which tries to either destroy or harm humanity in some way. Since artificial intelligence can be duplicated and may even be able to Lopez 2 duplicate itself, it would be near impossible to contain if it were to become malevolent and have the rights of a regular human adult. There could be no real to deter bad actions, as it could re-program itself to ignore any bad stimulus, and will easily out wait any sort of containment (such as prison) it may be subject to. From another side of influence, since it is artificial it must be man made, it cannot come to fruition naturally, so it may be biased either intentionally or unintentionally by its original programmer. Giving rights to AI in this case would compromise the integrity of voting, as a large software development company that specialized in AI might be able to stuff the ballot box with either measures or representatives that server for their benefit. To contrast, if an AI is developed to serve a purpose, and somehow starts to refuse to provide such utility, it would be unethical to force a corporation or any entity to continue putting resources towards it to support its continuing existence without productivity. This was stipulated in a Forbes article about AI in where the author poses what would happen if an AI designed for nuclear safety decides that want to design nuclear power plants. It wants to make music and go on tour, (Knapp), in which the company would be responsible to enable its behavior and even putting the program into a dormant state might equate to murder, if it is afforded rights. Many scholars argue that artificial intelligence must be afforded rights as abusing it is more akin to abusing a child, rather than abusing a car or other practical object. Very well analogized by a computer scientist as ought not to rev the engine so hard or spin the contains a not a (Whitby 327) in reference to someone giving advice to the heavy handling of a car. This argument has many flaws in it, starting with the intentions and objectives of raising children as opposed to creating an AI, in Lopez 3 which children are raised to become independent human beings an essentially a living legacy of oneself, while AI is used to find patterns and correlate data at a large level un-achievable by humans. Which means that a human child is given higher moral worth because it is an independent autonomous living entity, as opposed to a software product developed for a purpose in mind. Secondly, a huge flaw in this argument is that children are not afforded the full rights of a human being either, but they are given protections against abuse. There is no problem with giving AI adequate and sensible protections against actual abuse, but this does not necessitate giving it rights. Thirdly, how would it be moral or even logical to extend rights to essentially digital chips, when society denies it to a considerable subset of its own population. Another large concern about AI is the susceptibility and security of computers that it may be in charge of managing, or that they are residing on. Computers are notoriously hard to secure, which is what leads to many concerns about securing critical infrastructure such as power grids, water, communications systems and even shipping distribution. To add onto that there was many concerns because of the computerized ballot counting systems used in the presidential election, whether the results were free from foreign government meddling, in the form of state-sponsored hacking. Artificial intelligence will be able to seamlessly communicate with these systems as it is also a digital system, so it will be able to understand it at a level humans probably can never reach. Combining this with the freedom of giving it equal rights as humans would lead to the possibility where it can take over these systems and start causing catastrophes at a larger scale than anything else possible. It essentially could weaponize a infrastructure or even keep it hostage to meet its demands, and it would be much more dangerous than any conventional weapons as they are limited to their physical characteristics. Guns can only hold a finite amount Lopez 4 of bullets and shoot within a small radius, and even nuclear weapons are limited in their blast radius, but a concerted attack on the life supporting infrastructure of society would be much larger and indiscriminate. This is a threat to society which far outweighs any possible ethical concern of giving them rights, with the more practical concern of the survival of the human species. On the other hand, artificial intelligence itself will have to operate from a computer, which means that it cannot be perfectly secure. AI will most likely be developed by either a corporation or an amateur programmer which both will not be concerned about the true safety or perfection of the artificial intelligence, rather focusing on whether it output meets the requirements. This will obviously allow bugs and even security holes to be present in such system allowing it to be commandeered by a hacker. This problem would become accelerated and exacerbated by the notion that artificial intelligence has rights, because then it becomes a much more valuable target to hack. Examples include being able to manipulate elections as stipulated before, but also in any other binding decisions that it may be able to make with its rights, such as choosing a certain contractor or corporation on behalf of the developer. Scholars also raise a point that not giving artificial intelligence rights is essentially a new form a discrimination termed because denying them based upon their material makeup is unfair. This claim however is dangerous and counter-intuitive, as humans have more inherent value than their artificial counterparts, namely in terms of replaceability. In one case, soldiers deployed to unstable regions make routine use of bomb disposal robots. While these robots are controlled by a human, they have become anthropomorphized (given human qualities). This has gone to the extent that soldiers will risk their own lives instead of the robot, as they have created a bond with it as a pet or fellow soldier. However this obviously is much more Lopez 5 dangerous and much more costly, as a life and limb are much more valuable than the parts of a robot. As said by a comprehensive article in The New Yorker is not easy to love the life of a fish, in part because fish seem very enamored of life themselves. What moral interest could they hold for (Heller) which expresses clearly both the moral standing both AI and animals share. To go further, human life is valued above animals as well so the notion of being limited to just AI is incorrect, and giving either rights equal to humans would lead to abhorrent situations in which a human life was lost due to preferring either over them. In conclusion, strong AI does not need nor deserve rights, it is meant as a utility for humans, and as it is an extension rather than a separate entity it cannot be granted rights. People have forgotten what defines technology, it is an aid and extension to human physical and mental strength. There needs to be more concern for the self-preservation of the human species and even the preservation of natural life. There is no pressing need for strong AI, and proposals for applications of a replacement for human companionship seem very infeasible and do not outweigh the risks associated with creating one. Instead of considering whether AI should have rights, computer scientists should consider placing a moratorium on the development and research of strong AI, until there is a true application/need and protections put in place to mitigate the risks. While many say that technology controls peoples lives today, allowing AI to have rights would truly allow this statement to manifest in the worst ways. Lopez 6 Works Cited Dumas, Lloyd J. Technology Trap: Where Human Error and Malevolence Meet Powerful Praeger, 2010. 116-133. Heller, Nathan. If Animals Have Rights, Should  The New Yorker. The New Yorker, 17 Nov. 2016. Web. 15 Apr. 2017. Knapp, Alex. Should Artificial Intelligences Be Granted Civil  Forbes. Forbes Magazine, 09 Aug. 2011. Web. 15 Apr. 2017. Schwitzgebel, Eric, and Mara Garza. A Defense Of The Rights Of Artificial  Midwest Studies In Philosophy 39.1 (2015): 98-119. Smith, Wesley J. AI Machines: Things Not  First Things. The Institute on Religion and Public Life, 10 Apr. 2015. Web. 15 Apr. 2017. Whitby, Blay. Sometimes Hard To Be A Robot: A Call For Action On The Ethics Of Abusing Artificial  Interacting With Computers 20. Special Issue: On the Abuse and Misuse of Social Agents (2008): 326-333.