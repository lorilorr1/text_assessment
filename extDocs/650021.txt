Elsner 1 Dylan Elsner Kristen Rouisse ENC1102 29 January 2017 The Road to Self-Driving Cars The idea of autonomous vehicles has interested humanity for ages; the concept has been making appearances in science fiction since before the Jetsons. Self-driving cars have never been closer to society than today; with the technology giant Tesla leading the development of super intelligent vehicles. The company faces constant problems with the current infrastructure of driver oriented roads. It is absolutely possible to integrate self-driving and assisted driving cars into the current roads, however, it would require all drivers to convert their vehicles to the new system. Therefore, if the public desires for automated vehicles to become commonplace in America, a compromise must be met between Tesla Motors and the National Highway Traffic Safety Administration. Despite automated driving being in its infancy, Tesla Motors has already implemented their feature in all of their cars. The company touts that this assisted driving mode is much safer than driving manually; the features of the system includes speed to traffic conditions, keep within a lane, automatically change lanes without requiring driver (Tesla) among other self-driving abilities. It is true that all available Tesla cars have the autopilot feature, however, that may not be the driving force of sales. Tesla also prides itself in being the leading developer of fully electric cars. Energy efficiency is the focus of Tesla vehicles, as evidenced by the name, but automated driving is certainly a selling point that catches eyes. Consumers are interested in vehicles doing the leg-work of driving, but some are anxious Elsner 2 that it may be coming too quickly. Due to the overwhelming majority of drivers who lack assisted driving features, it is absolutely possible for the autopilot system to make mistakes. The technology behind the autopilot feature is not perfect, and as it becomes more common on the road, several incidents have brought the system under scrutiny. Last May, an accident occurred while a driver was using the autopilot feature of his Tesla Model S. Tragically, the autopilot systems to distinguish a large white 18-wheel truck and trailer crossing the (Yadron) and the vehicle drove directly into it, killing the driver. Elon Musk, the CEO of Tesla Motors, has spoken about the event and what they believe may have caused the crash, the autopilot system that blocks out overhead signs and such as bridges to avoid triggering false (Reuters) ignored the trailer. The event, although terrible, is the first death directly caused by an autonomous driving system; the company has already updated their autopilot feature to prevent such accidents from happening again. Consumers need to keep events such as the May accident in their minds as the technology becomes more attractive. In this case, Tesla was very fast to respond to the event, and companies need to be held to a similar standard in the future. Some groups believe that the company got off too easy, saying, should have been held accountable for the (Levin) This accident is an excellent example of an issue Tesla will face in the future. When there is an accident involving self-driving cars, society needs to decide on who should be held accountable. Some groups say Tesla was at fault for advertising their system in a deceptive way, meaning that the company should be punished. However, if the technology were advertised as assisted driving, then the blame should be placed on complacent drivers. Accidents such as the event in May haves highlighted the need for the NHTSA to collaborate with Tesla Motors to create safe roadways for all commuters. The National Highway Elsner 3 Traffic Safety Administration will need to borrow the scale created Society of Automotive Engineers, or SAE, for the compromise to work. SAE International worked to create a detailed list of different levels of automated and assisted driving ranging from level 1 to level 5. This scale has already been adopted by the Department of Transportation, which lends to its relevance in the compromise. The SAE itself holds no power in the execution or legislation involved in the roadways, nor do they aid in the development of the technology. Still, the automated driving scale they created can be used to help Tesla and the NHTSA safely deploy automated vehicles into the current infrastructure. The NHTSA should restrict automation to level 2 on the SAE scale: partial automation. Level 2 is a perfect middle ground for Tesla and the NHTSA; driving mode-specific execution by one or more driver assistance systems of both steering and acceleration/deceleration using information about the driving environment and with the expectation that the human driver performs all remaining aspects of the dynamic driving (SEA) this description is identical to the current state of autopilot, which means the company does need to issue any recalls. It also allows the NHTSA to place a non-arbitrary cap on how advanced the technology on the roads can be, anything above level 2 could pose a threat as it forces drivers to take a backseat to unfinished technology. The most important part in developing this technology is the safety of the passengers of the vehicle. This compromise allows for Tesla to temporarily shift their focus to developing affordable assisted driving systems; thus, every driver could have access to a safer form of transportation. Much of the public is anxious that automated driving would pose a threat to drivers without that technology. Professionals are that consumers are being sold a pile of promises about unproven (Consumer Reports) which will ultimately result in more serious injuries and fatalities. Despite that, it will still be safer than the current, manual Elsner 4 system. The NHTSA will need to restrict features that encourage distracted driving, but still allow for the development of self-driving cars. Although this compromise seems contradictory, the most important part of developing this technology is that those who are in the vehicle are safe. Assisted driving should not be advertised as automated driving, and it is in the best interest to prevent the two from mixing; the transition from the current driving system to self- driving cars needs to be done in phases, not in a slow shift. Tesla Motors continues to make massive strides with their autopilot system, and as older companies begin to explore similar technologies it is important to treat assisted driving as a tool for safety, rather than a luxury that allows for distracted driving. It will be the responsibility of the NHTSA to ensure that drivers will be safe riding in vehicles with high SAE ratings, and that begins with the proposed compromise. If the stakeholders start with a maximum of level 2, the majority of the public will have access to much safer technology before fully automated vehicles take to the road. In addition to placing restrictions on how quickly different levels of automation can be sold by producers, consumers need to be reminded to be completely aware of the road until full automation is tested and available. The collaboration between the National Highway Traffic Safety Administration and Tesla Motors may result in future generations never even touching a steering wheel, a time free of highway fatalities. Elsner 5 Works Cited About SAE  Current SAE News Releases. N.p., n.d. Web. 12 Feb. 2017.  Autopilot Tesla. N.p., n.d. Web. 12 Feb. 2017 Reports, Consumer. Autopilot: Too Much Autonomy Too  Consumer Reports. N.p., n.d. Web. 12 Feb. 2017. Levin, Alan, and Ryan Beene. Sigh of Relief for Self-Driving Cars as Tesla Cleared in  Bloomberg.com. Bloomberg, 19 Jan. 2017. Web. 29 Jan. 2017. Tesla considering two theories that may explain fatal Model S  The Guardian. Guardian News and Media, 29 July 2016. Web. 29 Jan. 2017. Yadron, Danny, and Dan Tynan. Tesla driver dies in first fatal crash while using autopilot  The Guardian. Guardian News and Media, 30 June 2016. Web. 29 Jan. 2017.